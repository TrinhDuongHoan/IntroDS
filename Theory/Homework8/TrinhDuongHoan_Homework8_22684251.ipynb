{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://sites.google.com/view/trinh-duong-hoans-site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm findall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'my', 'name', 'is', 'Hoan', 'I', 'm', '21', 'years', 'old']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hàm trả về tất cả chuỗi con có định dạng khớp với mẫu \n",
    "text = \"Hello my name is Hoan. I'm 21 years old\"\n",
    "f = re.findall(r'\\w+',text)\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm compile**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hoan']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hàm compile :  Biên dịch một biểu thức chính quy thành một đối tượng pattern.\n",
    "pat = re.compile(r'hoan')\n",
    "text = 'hoan is a good data engineer'\n",
    "f = pat.findall(text)\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['orange', 'apple', 'banana']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hàm split : Tách chuỗi thành một danh sách các phần dựa trên biểu thức chính quy\n",
    "text = \"orange, apple, banana\"\n",
    "result = re.split(r',\\s*|\\s+', text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm sub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100 apple 100 banana 100 orange'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hàm sub : Thay thế tất cả các chuỗi khớp với biểu thức bằng chuỗi cho trước\n",
    "text = '1 apple 2 banana 3 orange'\n",
    "result = re.sub(r'\\d+','100',text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm escape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\[team1\\\\]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hàm escape : Trả về một chuỗi với tất cả các ký tự đặc biệt được tránh để chúng có thể được sử dụng trong biểu thức chính quy.\n",
    "pat = re.escape(r'[team1]')\n",
    "pat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hàm search : Tìm kiếm vị trí xuất hiện đầu tiên của chuỗi theo mẫu trong chuỗi ban đầu\n",
    "text = 'Hoan Ban Ha Hoan Vu Hoan' \n",
    "result = re.search(r'Hoan',text)\n",
    "result.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found at the beginning.\n"
     ]
    }
   ],
   "source": [
    "# Hàm match : Tìm kiếm xem có khớp từ đầu chuỗi không.\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "match = re.match(r'The', text)\n",
    "if match:\n",
    "    print(\"Match found at the beginning.\")  # Output: Match found at the beginning.\n",
    "else :\n",
    "    print(\"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1\n",
    "def email_extraction (text : str) :\n",
    "    result = re.findall(r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}', text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trinhduonghoan2004@gmail.com', '22684251.hoan@student.iuh.edu.vn']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2\n",
    "text = 'trinhduonghoan2004@gmail.com, 22684251.hoan@student.iuh.edu.vn, hehehe'\n",
    "email_extraction(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Web Scraping with Python\" là hướng dẫn toàn diện về cách sử dụng Python để trích xuất dữ liệu từ web. Cuốn sách tập trung vào việc sử dụng các thư viện như BeautifulSoup và Scrapy để tự động hóa quá trình web scraping. Chúng ta sẽ học cách phân tích cấu trúc HTML của một trang web và trích xuất dữ liệu cần thiết từ đó.\n",
    "Cuốn sách cung cấp các ví dụ thực tế và hướng dẫn cụ thể để bạn có thể áp dụng các kỹ thuật web scraping vào dự án của mình. Ngoài ra, sách cũng đề cập đến các vấn đề pháp lý và etic khi sử dụng web scraping để đảm bảo bạn hoạt động trong giới hạn pháp luật. Bạn sẽ học cách sử dụng XPath và CSS selectors để chọn các phần tử HTML cụ thể trên một trang web. Thêm vào đó, cuốn sách đi sâu vào các chiến lược tiếp cận và kỹ thuật để xử lý các trang web động và bảo mật cao. Nó cung cấp hướng dẫn cách lưu trữ dữ liệu thu thập được và làm thế nào để xử lý các dữ liệu lớn. Hơn nữa, Cuốn sách giới thiệu cách sử dụng các công cụ như Selenium để tương tác với JavaScript và các ứng dụng web động. Nó cung cấp các bài học về cách xử lý các lỗi và ngoại lệ trong quá trình web scraping. Chúng ta sẽ học cách xây dựng các spider và crawlers để tự động hóa quá trình thu thập dữ liệu trên các trang web lớn. Cuốn sách cung cấp các gợi ý và các chiến lược để tối ưu hóa hiệu suất và độ tin cậy của các ứng dụng web scraping của bạn. Nó cung cấp các ví dụ về việc sử dụng API và RSS feeds để thu thập dữ liệu từ các nguồn có cấu trúc. Cuối cùng, cuốn sách tóm tắt các bước cần thiết để triển khai và duy trì các ứng dụng web scraping."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
